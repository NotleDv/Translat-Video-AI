{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b56b3c23",
   "metadata": {},
   "source": [
    "### üõ†Ô∏è Configura√ß√£o de device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecf9293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "n_devices = torch.cuda.device_count()\n",
    "\n",
    "device_ = \"cpu\" if not n_devices else \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ff9b82",
   "metadata": {},
   "source": [
    "### üóÉÔ∏è Recuperando o log do notebook 01_EA_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d534a8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bc473eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_video = \"/home/elton/Projetos/Translater_Video/teste\"\n",
    "name_video = \"1 - Preparations.mp4\"\n",
    "\n",
    "name_audio_out = \"audio_completo.wav\"\n",
    "path_out = \"/home/elton/Projetos/Translater_Video/teste/resultado_teste\"\n",
    "\n",
    "path_log = os.path.join(path_out, 'log', 'log.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55a6f41d",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/elton/Projetos/Translater_Video/teste/resultado_teste/log/log.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m log \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpath_log\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m      3\u001b[0m     log \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n",
      "File \u001b[0;32m~/Projetos/Translater_Video/.venv_core/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/elton/Projetos/Translater_Video/teste/resultado_teste/log/log.json'"
     ]
    }
   ],
   "source": [
    "log = ''\n",
    "with open(path_log, 'r', encoding='utf-8') as file:\n",
    "    log = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bb25f1",
   "metadata": {},
   "source": [
    "### üîÑ Tradu√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "945ca8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ling_input = 'en'\n",
    "ling_output = 'pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af4d303b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elton/Projetos/Translater_Video/.venv_core/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-09-04 16:35:10.071512: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-09-04 16:35:10.162210: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-09-04 16:35:11.888771: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1285d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\")\n",
    "tokenizer = M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2bc27992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traducao (texto, lang_origem, lang_destino):\n",
    "    tokenizer.src_lang = lang_origem # Idioma de origem\n",
    "    encoded_hi = tokenizer(texto, return_tensors=\"pt\")\n",
    "    generated_tokens = model.generate(**encoded_hi, forced_bos_token_id=tokenizer.get_lang_id(lang_destino)) # Idioma Destino\n",
    "    traducao = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "    \n",
    "    return traducao[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2b636b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, i in enumerate(log):\n",
    "    texto = i['text_origem']\n",
    "    \n",
    "    result = traducao(texto, ling_input, ling_output)\n",
    "    \n",
    "    log[index]['text_destino'] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9a42c5a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start': 6.92,\n",
       " 'end': 29.87,\n",
       " 'path_audio': '/home/elton/Projetos/Translater_Video/teste/resultado_teste/audios/separados_01/0.wav',\n",
       " 'text_origem': \" Before we can begin, it is necessary that both Cinema 4D and Redshift are already installed. We will do this, of course, via the Maxon app, as I'm sure you know. You can find the Maxon app directly on the Maxon website. We go to Products, directly to Downloads, and then you can download the app right up here. For Windows, Mac or Linux, you can also download it here below. Then we open the app.\",\n",
       " 'text_destino': 'Antes que possamos come√ßar, √© necess√°rio que tanto Cinema 4D e Redshift j√° estejam instalados. faremos isso, √© claro, atrav√©s da aplica√ß√£o Maxon, como eu sei. Voc√™ pode encontrar a aplica√ß√£o Maxon diretamente no site Maxon. N√≥s vamos para Produtos, diretamente para Downloads, e ent√£o voc√™ pode baixar a aplica√ß√£o diretamente aqui. Para Windows, Mac ou Linux, voc√™ tamb√©m pode baixar aqui abaixo.'}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2942629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (path_log, 'w', encoding='utf-8') as file:\n",
    "    file.write(json.dumps(log, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45930f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.configs import torch_config, read_json, write_json\n",
    "import torch  \n",
    "    \n",
    "def translat (text:str):\n",
    "    from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
    "    import logging\n",
    "    logger = logging.getLogger('M2M100ForConditionalGeneration') \n",
    "    logger = logging.getLogger('M2M100Tokenizer') \n",
    "    model = M2M100ForConditionalGeneration.from_pretrained(\"facebook/m2m100_418M\")\n",
    "    \n",
    "    tokenizer = M2M100Tokenizer.from_pretrained(\"facebook/m2m100_418M\")\n",
    "    \n",
    "    ling_input = 'en'  # <<--- Para futuras atualiza√ß√µes\n",
    "    ling_output = 'pt' # <<--- Para futuras atualiza√ß√µes\n",
    "    \n",
    "    tokenizer.src_lang = ling_input # Idioma de origem\n",
    "    encoded_hi = tokenizer(text, return_tensors=\"pt\")\n",
    "    generated_tokens = model.generate(**encoded_hi, forced_bos_token_id=tokenizer.get_lang_id(ling_output)) # Idioma Destino\n",
    "    traducao = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "    \n",
    "    return traducao[0]\n",
    "    \n",
    "            \n",
    "def main(path_log:str):\n",
    "    log = read_json(path_log)\n",
    "    \n",
    "    for index, i in enumerate(log[1]):\n",
    "        texto = i['text_origem']\n",
    "        \n",
    "        result = translat(texto)\n",
    "        \n",
    "        log[1][index]['text_destino'] = result\n",
    "    \n",
    "    write_json(path_log, log)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lab_Translat_Video",
   "language": "python",
   "name": "lab_translat_video"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
