{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b56b3c23",
   "metadata": {},
   "source": [
    "### üõ†Ô∏è Configura√ß√£o de device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecf9293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "n_devices = torch.cuda.device_count()\n",
    "\n",
    "device_ = \"cpu\" if not n_devices else \"cuda\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ff9b82",
   "metadata": {},
   "source": [
    "### üóÉÔ∏è Recuperando o log do notebook 01_EA_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed85ac81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3be2006",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_video = \"/home/elton/Projetos/Translater_Video/teste\"\n",
    "name_video = \"1 - Preparations.mp4\"\n",
    "\n",
    "name_audio_out = \"audio_completo.wav\"\n",
    "path_out = \"/home/elton/Projetos/Translater_Video/teste/resultado_teste\"\n",
    "path_out_audios = \"/home/elton/Projetos/Translater_Video/teste/resultado_teste/audios/gerados\"\n",
    "path_log = os.path.join(path_out, 'log', 'log.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d534a8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = ''\n",
    "with open(path_log, 'r', encoding='utf-8') as file:\n",
    "    log = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67585776",
   "metadata": {},
   "source": [
    "### üé∫ Remover ac√∫stica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfc8dc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 11:45:19.702846: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-27 11:45:19.936185: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-08-27 11:45:22.771317: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:spleeter:File output/audio_completo/vocals.wav written succesfully\n",
      "INFO:spleeter:File output/audio_completo/accompaniment.wav written succesfully\n",
      "INFO:spleeter:File /home/elton/Projetos/Translater_Video/teste/resultado_teste/audio_completo/vocals.wav written succesfully\n",
      "INFO:spleeter:File /home/elton/Projetos/Translater_Video/teste/resultado_teste/audio_completo/accompaniment.wav written succesfully\n"
     ]
    }
   ],
   "source": [
    "from spleeter.separator import Separator\n",
    "import soundfile as sf\n",
    "\n",
    "# Inicializa separador em 2 stems (voz e instrumental)\n",
    "separator = Separator('spleeter:2stems')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c93752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = os.path.join(path_out , name_audio_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c27e07e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Apply unet for vocals_spectrogram\n",
      "INFO:tensorflow:Apply unet for accompaniment_spectrogram\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from pretrained_models/2stems/model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 11:49:51.074035: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-08-27 11:49:51.074142: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:04:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-08-27 11:49:51.074158: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-27 11:49:52.883114: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_1' with dtype float and shape [8623373,2]\n",
      "\t [[{{node Placeholder/_1}}]]\n"
     ]
    }
   ],
   "source": [
    "# Separa em mem√≥ria\n",
    "prediction = separator.separate_to_file(a, path_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11f6761",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "807ccfbf",
   "metadata": {},
   "source": [
    "### Concatena√ß√£o 01\n",
    "`Concatena√ß√£o dos √°udios que vieram gerados de uma √∫nica frase`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "c13cb60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "08eb6b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "audios_posicionados = []\n",
    "\n",
    "for index, i in enumerate(log):\n",
    "    q_audios = len(i['path_audios_gerados'])\n",
    "    \n",
    "    if q_audios > 1:\n",
    "        name = []\n",
    "        concatenacao_audios = AudioSegment.empty()\n",
    "        \n",
    "        #Create Audio_Segments din√¢mico\n",
    "        for _, k in enumerate(i['path_audios_gerados']):\n",
    "            \n",
    "            name.append(list(k.keys()))\n",
    "            path_audio_atual = list(k.items())[0]\n",
    "            #list(k.keys())[0] = AudioSegment.from_file(path_audio_atual[1])\n",
    "            \n",
    "            concatenacao_audios += AudioSegment.from_file(path_audio_atual[1])\n",
    "\n",
    "            os.remove(path_audio_atual[1])\n",
    "            \n",
    "        #print(name[0][0])\n",
    "        path_f = os.path.join(path_out_audios, 'audio'+ name[0][0][6:] + '.wav')\n",
    "        concatenacao_audios.export(path_f, format='wav')\n",
    "        \n",
    "        \n",
    "        log[index]['path_audios_gerados'] = [{name[0][0]: path_f}]\n",
    "        # print(name[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1438ca0e",
   "metadata": {},
   "source": [
    "### Dura√ß√£o\n",
    "`Validando a dura√ß√£o dos √°udios gerados`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8081d5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7a9e98a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def leitura_wave (path):\n",
    "    with wave.open(path, 'rb') as wave_file:\n",
    "        frames = wave_file.getnframes()        # quantidade de frames (amostras)\n",
    "        rate = wave_file.getframerate()        # taxa de amostragem (frames por segundo)\n",
    "        duration = frames / float(rate)       # dura√ß√£o em segundos\n",
    "    return duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "c0d7422c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for log_idx, i in enumerate(log):\n",
    "    duracao_audios = 0\n",
    "    \n",
    "    for path in i['path_audios_gerados']:\n",
    "        for key, item in path.items():\n",
    "            duracao_audios += leitura_wave(item)\n",
    "\n",
    "    log[log_idx]['duracao_audio_gerado'] = round(float(duracao_audios), 2)\n",
    "    log[log_idx]['duracao_audio_original'] = round(float(i['end'] - i['start']), 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ba9b76",
   "metadata": {},
   "source": [
    "### Concatena√ß√£o 2\n",
    "`Gerando o √°udio para ser adicionar ao v√≠deo`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "11aa5ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "duracao_total_audio = ((log[-1]['end'] - log[-1]['start']) - log[-1]['duracao_audio_gerado']) + log[-1]['end']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ba8fe529",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = AudioSegment.empty()\n",
    "base = AudioSegment.silent(duration= int(duracao_total_audio * 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d2e18950",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ''\n",
    "\n",
    "for index, lista in enumerate(log):\n",
    "    time_start = int(lista['start'] * 1000)\n",
    "    time_end = int(lista['end'] * 1000)\n",
    "    \n",
    "    for _, item in enumerate(lista['path_audios_gerados']):\n",
    "        \n",
    "        if index == 0:\n",
    "            audio = audio.from_file(list(item.items())[0][1])\n",
    "            result = base.overlay(audio, position=time_start)\n",
    "        else:\n",
    "            time_start_anterior = int(log[index-1]['start'] * 1000)\n",
    "            time_end_anterior = int(log[index-1]['end'] * 1000)\n",
    "            \n",
    "            if time_end_anterior > time_start:\n",
    "                calc = time_end_anterior - time_start\n",
    "                time_start += time_start\n",
    "                \n",
    "                audio = audio.from_file(list(item.items())[0][1])\n",
    "                result = result.overlay(audio, position=time_start)\n",
    "            \n",
    "            else:\n",
    "                audio = audio.from_file(list(item.items())[0][1])\n",
    "                result = result.overlay(audio, position=time_start)\n",
    "    \n",
    "\n",
    "    path_f = os.path.join(path_out_audios, 'resultado.wav')\n",
    "    result.export(path_f, format='wav')\n",
    "    \n",
    "    log[index]['audio_concatenado'] = path_f\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b54dfff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_log, 'w', encoding='utf-8') as file:\n",
    "    file.write(json.dumps(log, ensure_ascii=False, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kernel_Translater_Video",
   "language": "python",
   "name": "kernel_translater_video"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
